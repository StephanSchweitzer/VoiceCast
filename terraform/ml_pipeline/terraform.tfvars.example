# ML Pipeline Configuration Example
# Copy these values to your main terraform.tfvars file and adjust as needed

# Uncomment and configure these variables for ML pipeline deployment
# ml_pipeline_enabled = true
# ml_pipeline_bucket_name = "your-project-ml-pipeline-bucket"
# vertex_ai_model_name = "voicecast-emotion-model"
# training_instance_type = "n1-standard-4"
# gpu_type = "NVIDIA_TESLA_K80"
# gpu_count = 1
# preemptible = true
# cloud_run_max_instances = 10
# cloud_run_memory = "2Gi"
# cloud_run_cpu = "1000m"
# bucket_lifecycle_days = 30
# allow_public_access = false
# ml_environment = "dev"

# Production example:
# ml_pipeline_enabled = true
# ml_pipeline_bucket_name = "voicecast-prod-ml-pipeline"
# vertex_ai_model_name = "voicecast-emotion-model-prod"
# training_instance_type = "n1-standard-8"
# gpu_type = "NVIDIA_TESLA_V100"
# gpu_count = 2
# preemptible = false
# cloud_run_max_instances = 50
# cloud_run_memory = "4Gi"
# cloud_run_cpu = "2000m"
# bucket_lifecycle_days = 90
# allow_public_access = true
# ml_environment = "prod"